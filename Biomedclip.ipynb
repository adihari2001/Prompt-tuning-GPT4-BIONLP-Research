{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsrlvjZtkg4J",
        "outputId": "62e786ce-bd88-4b69-d21e-63222459ca80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: open_clip_torch in /usr/local/lib/python3.10/dist-packages (2.24.0)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (0.17.1+cu121)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (2023.12.25)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (6.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (4.66.2)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (0.20.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (0.1.99)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (3.20.3)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (0.9.16)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.9.0->open_clip_torch) (12.4.99)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->open_clip_torch) (0.2.13)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open_clip_torch) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open_clip_torch) (6.0.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open_clip_torch) (24.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm->open_clip_torch) (0.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->open_clip_torch) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->open_clip_torch) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.0->open_clip_torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open_clip_torch) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open_clip_torch) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9.0->open_clip_torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install open_clip_torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "from open_clip import create_model_from_pretrained, get_tokenizer\n"
      ],
      "metadata": {
        "id": "Rns-wPWumygW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, preprocess = create_model_from_pretrained('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')\n",
        "tokenizer = get_tokenizer('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVeC3PG-w0Vw",
        "outputId": "7eda7d82-96ab-457a-a009-30781f96e490"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV file containing image-text pairs\n",
        "df = pd.read_csv('/content/drive/MyDrive/Biomedclip/amboss_image_data_all_results.csv')\n"
      ],
      "metadata": {
        "id": "_qq0f-aT1C-P"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "image_embeddings = []\n",
        "for index, row in df.iterrows():\n",
        "    image_path = os.path.join(\"/content/drive/MyDrive/Biomedclip\",row['subfolder'], f\"{row['id']}.jpg\")\n",
        "    # Load and preprocess the image\n",
        "    image = Image.open(image_path)\n",
        "    image = preprocess(image)\n",
        "    image_tensor = torch.Tensor(np.array(image))\n",
        "\n",
        "# Add batch dimension to the image\n",
        "    image_tensor = image_tensor.unsqueeze(0)\n",
        "    # Compute embeddings for the image\n",
        "    with torch.no_grad():\n",
        "        image_embedding = model.encode_image(image_tensor)\n",
        "    #text_tokens = tokenizer(row['hint'])\n",
        "    #text_embedding = model.encode_text(text_tokens)\n",
        "    image_embeddings.append((image_embedding, row['id']))"
      ],
      "metadata": {
        "id": "YC7cMrwqyYdM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Store image embeddings to a file\n",
        "with open('/content/drive/MyDrive/Biomedclip/image_embeddings.pkl', 'wb') as f:\n",
        "    pickle.dump(image_embeddings, f)\n"
      ],
      "metadata": {
        "id": "N-GeMnTT3UjB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Retrieve image embeddings from file\n",
        "with open('/content/drive/MyDrive/Biomedclip/image_embeddings.pkl', 'rb') as f:\n",
        "    image_embeddings = pickle.load(f)\n",
        "\n",
        "# Now image_embeddings contains the list of image embeddings along with their corresponding IDs\n"
      ],
      "metadata": {
        "id": "gYh-M_l23XnU"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_image = Image.open('/content/drive/MyDrive/Biomedclip/query_image_2.jpeg')\n",
        "query_image = preprocess(query_image)"
      ],
      "metadata": {
        "id": "LbP3i2d_sLn6"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "# Convert PIL image to PyTorch tensor\n",
        "query_image_tensor = torch.Tensor(np.array(query_image))\n",
        "\n",
        "# Add batch dimension to the image\n",
        "query_image_tensor = query_image_tensor.unsqueeze(0)\n",
        "\n",
        "# Now you can pass the reshaped image tensor to the encode_image method\n",
        "\n",
        "with torch.no_grad():\n",
        "    query_image_embedding = model.encode_image(query_image_tensor)"
      ],
      "metadata": {
        "id": "uVqYnqemx_i7"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarities = []\n",
        "for image_embedding,id in image_embeddings:\n",
        "    similarity_score = torch.cosine_similarity(query_image_embedding, image_embedding)\n",
        "    similarities.append((id, similarity_score))\n",
        "\n",
        "# Sort pairs based on similarity and retrieve top k pairs\n",
        "k = 3\n",
        "top_k_pairs = sorted(similarities, key=lambda x: x[1], reverse=True)[:k]\n",
        "\n",
        "# Print top k pairs\n",
        "for pair in top_k_pairs:\n",
        "    print(f\"Image: {pair[0]}, Similarity Score: {pair[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wW6vK8A0YR0",
        "outputId": "71c0a037-10eb-4472-f0ee-999030a4998b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 716, Similarity Score: tensor([0.8072])\n",
            "Image: 3, Similarity Score: tensor([0.8063])\n",
            "Image: 891, Similarity Score: tensor([0.7958])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for pair in top_k_pairs:\n",
        "  my_id_value = pair[0]\n",
        "  hint_value = df.loc[df['id'] == my_id_value, 'hint'].values[0]\n",
        "  print(hint_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMsalPRx2vTV",
        "outputId": "42336404-313d-4abb-cf66-7742e9d6ce26"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The hand is covered with light brown papules and rough, hyperkeratotic plaques. This condition is the result of years of exposure to sunlight without protection.\n",
            "A rash on the hands, feet, and mouth is typical of this pediatric febrile exanthem.\n",
            "This patient's history of extensive sun exposure and hyperpigmented macules and patches are most consistent with solar lentigo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6vxkFaf16uQI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}